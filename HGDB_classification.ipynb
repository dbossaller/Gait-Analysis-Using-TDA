{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from gait_pipeline import entropy_dataframe\n",
    "from construct_dataset import load_data_from_json\n",
    "\n",
    "\n",
    "filename = './Datasets/left_thigh_1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = load_data_from_json(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c00322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate persistence diagram entropies, takes ~10 minutes to calculate.\n",
    "\n",
    "entropies_df = entropy_dataframe(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e874c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = './Datasets/Entropies/lt1.json'\n",
    "with open(filename, 'w+') as fp:\n",
    "    json.dump(entropies_df, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3898bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from construct_dataset import read_data_json\n",
    "from gait_pipeline import make_entropy_dataframe\n",
    "\n",
    "entropies = read_data_json('./Datasets/Entropies/lt1.json')\n",
    "entropy_df = make_entropy_dataframe(entropies)\n",
    "\n",
    "for key in full_dataset.keys():\n",
    "    entropy_df[f'sub{key}'] = entropy_df['subject'].apply(lambda x: True if x == key else False)\n",
    "\n",
    "entropy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "filename = './Reports/lt1.txt'\n",
    "if os.path.isfile(filename):\n",
    "    os.remove(filename)\n",
    "        \n",
    "for key in full_dataset.keys():\n",
    "    X = entropy_df[['H0 Entropy','H1 Entropy', 'H2 Entropy']]\n",
    "    y = entropy_df[f'sub{key}']\n",
    "\n",
    "    X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=.33)\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    Title = f'Subject {key} Classification Report'\n",
    "    ClassRpt = classification_report(y_test, y_pred, zero_division = 0)\n",
    "    ConMtx = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "    with open(filename, 'a+') as fp:\n",
    "        fp.write(Title+'\\n')\n",
    "        fp.write(str(ClassRpt)+'\\n')\n",
    "        fp.write(str(ConMtx)+'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa128d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugait-tda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
